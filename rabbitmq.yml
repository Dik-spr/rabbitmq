# Готовим аккаунт с ролями для авторизации подов rabbitmq в кластере k8s
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rabbitmq

---

kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: endpoint-reader
subjects:
  - kind: ServiceAccount
    name: rabbitmq
    namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: endpoint-reader

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: endpoint-reader
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get"]

---
# Готовим configMap для каждой реплики rabbitmq с подключенными модулями для работы в k8s

apiVersion: v1
kind: ConfigMap
metadata:
  name: rabbitmq-config
data:
  enabled_plugins: |
      [rabbitmq_peer_discovery_k8s,rabbitmq_federation_management,rabbitmq_management].
  rabbitmq.conf: |
      ## Cluster formation. See http://www.rabbitmq.com/cluster-formation.html to learn more.
      cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s
      cluster_formation.k8s.host = kubernetes.default
      ## Should RabbitMQ node name be computed from the pod's hostname or IP address?
      ## IP addresses are not stable, so using [stable] hostnames is recommended when possible.
      ## Set to "hostname" to use pod hostnames.
      ## When this value is changed, so should the variable used to set the RABBITMQ_NODENAME
      ## environment variable.
      cluster_formation.k8s.address_type = ip
      ## How often should node cleanup checks run?
      cluster_formation.node_cleanup.interval = 30
      ## Set to false if automatic removal of unknown/absent nodes
      ## is desired. This can be dangerous, see
      ##  * http://www.rabbitmq.com/cluster-formation.html#node-health-checks-and-cleanup
      ##  * https://groups.google.com/forum/#!msg/rabbitmq-users/wuOfzEywHXo/k8z_HWIkBgAJ
      cluster_formation.node_cleanup.only_log_warning = true
      cluster_partition_handling = autoheal
      ## See http://www.rabbitmq.com/ha.html#master-migration-data-locality
      queue_master_locator=min-masters
      ## See http://www.rabbitmq.com/access-control.html#loopback-users
      loopback_users.guest = false

---
# Цепляем к кластеру rabbitmq сервис с итерфейсным и админским портами
kind: Service
apiVersion: v1
metadata:
  name: rabbitmq
  labels:
    app: rabbitmq
spec:
  clusterIP: None
  ports:
    - name: amqp
      protocol: TCP
      port: 5672
      targetPort: 5672
    - name: admin
      protocol: TCP
      port: 15672
      targetPort: 15672
  selector:
    app: rabbitmq

---
# пробрасываем с помощью ингресса админский порт на внешний адрес
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: rabbitmq
spec:
  rules:
  - http:
      paths:
      - backend:
          serviceName: rabbitmq
          servicePort: 15672

---
# Так как каждый экземпляр rabbitmq должен сохранять свое состояние то для его развертывания
# лучше использовать не Deployment а StatefulSet, что гарантирует собственный claim volume у каждой реплики,
# которая сохраняется даже после удаления пода с rabbitmq.

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: rabbitmq
spec:
  serviceName: rabbitmq
  replicas: 3  # создаем три реплики rabbitmq
  selector:
    matchLabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
    spec:
      serviceAccount: rabbitmq
      terminationGracePeriodSeconds: 10
# Описываем шаблон контейнера 
      containers:
        - name: rabbitmq-k8s
          image: rabbitmq:3.7-management
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
            - name: RABBITMQ_NODENAME
              value: "rabbit@$(MY_POD_IP)"
            - name: K8S_SERVICE_NAME
              value: "rabbitmq"
            - name: RABBITMQ_ERLANG_COOKIE
              value: "mycookie"
# Описываем интерфейсный и админские порты
          ports:
            - name: amqp
              protocol: TCP
              containerPort: 5672
            - name: admin
              protocol: TCP
              containerPort: 15672
# Описываем пробы, следящие за жизнью пода
          livenessProbe:
            exec:
              command: ["rabbitmqctl", "status"]
            initialDelaySeconds: 60
            periodSeconds: 60
            timeoutSeconds: 15
          readinessProbe:
            exec:
              command: ["rabbitmqctl", "status"]
            initialDelaySeconds: 20
            periodSeconds: 60
            timeoutSeconds: 10
          imagePullPolicy: Always
# Подключаем к поду конфиг и том для данных
          volumeMounts:
            - name: config-volume
              mountPath: /etc/rabbitmq
            - name: data
              mountPath: /var/lib/rabbitmq
      volumes:
        - name: config-volume
          configMap:
            name: rabbitmq-config
            items:
              - key: rabbitmq.conf
                path: rabbitmq.conf
              - key: enabled_plugins
                path: enabled_plugins
# Создаем афинити для подняти, по возможности, только по одному поду на каждой ноде кластера k8s
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - rabbitmq
                topologyKey: kubernetes.io/hostname
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 20Gi